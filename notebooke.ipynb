{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets transformers evaluate seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">For the indentification of mountain names inside the text we use [Few-NERD](http://ningding97.github.io/fewnerd) dataset, which is also available at [Kaggle](http://www.kaggle.com/datasets/nbroad/fewnerd). More exactly we use a supervised part of this dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 131766\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 18823\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 37647\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fewnerd = load_dataset('json', data_files={\n",
    "    'train': './fewnerd/supervised/train.json',\n",
    "    'val': './fewnerd/supervised/dev.json',\n",
    "    'test': './fewnerd/supervised/test.json',\n",
    "})\n",
    "fewnerd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Loading tag dictionaries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'O', '1': 'art', '2': 'building', '3': 'event', '4': 'location', '5': 'organization', '6': 'other', '7': 'person', '8': 'product'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'art-broadcastprogram',\n",
       " '2': 'art-film',\n",
       " '3': 'art-music',\n",
       " '4': 'art-other',\n",
       " '5': 'art-painting',\n",
       " '6': 'art-writtenart',\n",
       " '7': 'building-airport',\n",
       " '8': 'building-hospital',\n",
       " '9': 'building-hotel',\n",
       " '10': 'building-library',\n",
       " '11': 'building-other',\n",
       " '12': 'building-restaurant',\n",
       " '13': 'building-sportsfacility',\n",
       " '14': 'building-theater',\n",
       " '15': 'event-attack/battle/war/militaryconflict',\n",
       " '16': 'event-disaster',\n",
       " '17': 'event-election',\n",
       " '18': 'event-other',\n",
       " '19': 'event-protest',\n",
       " '20': 'event-sportsevent',\n",
       " '21': 'location-GPE',\n",
       " '22': 'location-bodiesofwater',\n",
       " '23': 'location-island',\n",
       " '24': 'location-mountain',\n",
       " '25': 'location-other',\n",
       " '26': 'location-park',\n",
       " '27': 'location-road/railway/highway/transit',\n",
       " '28': 'organization-company',\n",
       " '29': 'organization-education',\n",
       " '30': 'organization-government/governmentagency',\n",
       " '31': 'organization-media/newspaper',\n",
       " '32': 'organization-other',\n",
       " '33': 'organization-politicalparty',\n",
       " '34': 'organization-religion',\n",
       " '35': 'organization-showorganization',\n",
       " '36': 'organization-sportsleague',\n",
       " '37': 'organization-sportsteam',\n",
       " '38': 'other-astronomything',\n",
       " '39': 'other-award',\n",
       " '40': 'other-biologything',\n",
       " '41': 'other-chemicalthing',\n",
       " '42': 'other-currency',\n",
       " '43': 'other-disease',\n",
       " '44': 'other-educationaldegree',\n",
       " '45': 'other-god',\n",
       " '46': 'other-language',\n",
       " '47': 'other-law',\n",
       " '48': 'other-livingthing',\n",
       " '49': 'other-medical',\n",
       " '50': 'person-actor',\n",
       " '51': 'person-artist/author',\n",
       " '52': 'person-athlete',\n",
       " '53': 'person-director',\n",
       " '54': 'person-other',\n",
       " '55': 'person-politician',\n",
       " '56': 'person-scholar',\n",
       " '57': 'person-soldier',\n",
       " '58': 'product-airplane',\n",
       " '59': 'product-car',\n",
       " '60': 'product-food',\n",
       " '61': 'product-game',\n",
       " '62': 'product-other',\n",
       " '63': 'product-ship',\n",
       " '64': 'product-software',\n",
       " '65': 'product-train',\n",
       " '66': 'product-weapon'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./fewnerd/id2coarse_tags.json\", \"r\") as f:\n",
    "    id2coarse_tag = json.load(f)\n",
    "print(id2coarse_tag)\n",
    "    \n",
    "with open(\"./fewnerd/id2fine_tags.json\", \"r\") as f:\n",
    "    id2fine_tag = json.load(f)\n",
    "id2fine_tag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, [46, 75, 98, 138, 284])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOUTAIN_TAG = 24\n",
    "\n",
    "rows_with_mountain_tag = [i for i, row in enumerate(fewnerd[\"train\"][\"fine_tags\"]) if MOUTAIN_TAG in row]\n",
    "len(rows_with_mountain_tag), rows_with_mountain_tag[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Some examples from the train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'Eighth', 'Army', 'began', 'to', 'attack', 'Italian', 'units', ',', 'located', 'using', 'information', 'from', 'Ultra', ',', 'at', 'Ruweisat', 'Ridge', 'and', 'from', 'again', 'at', 'Tel', 'El', 'Eisa', 'on', '22', 'July', 'and', 'Miteirya', 'Ridge', 'after', 'which', 'another', 'lull', 'fell', '.'], 'coarse_tags': [0, 5, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0], 'fine_tags': [0, 32, 32, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 21, 21, 21, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 0, 0], 'id': '46'} \n",
      "\n",
      "{'tokens': ['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'], 'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0], 'fine_tags': [0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0], 'id': '75'} \n",
      "\n",
      "{'tokens': ['Mount', 'Diablo', 'has', 'inspired', 'many', 'artists', 'and', 'writers', '.'], 'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 24, 0, 0, 0, 0, 0, 0, 0], 'id': '98'} \n",
      "\n",
      "{'tokens': ['K2', 'is', 'further', 'north', 'than', 'the', 'Himalayan', 'mountains', 'so', 'the', 'climate', 'is', 'colder', ';', 'the', 'Karakoram', 'range', 'is', 'wider', 'than', 'the', 'Himalayan', 'so', 'more', 'ice', 'and', 'snow', 'is', 'trapped', 'there', '.'], 'coarse_tags': [4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': '138'} \n",
      "\n",
      "{'tokens': ['The', 'North', 'Lyell', 'Mine', ',', 'scene', 'of', 'the', '1912', 'North', 'Mount', 'Lyell', 'Disaster', 'was', 'at', 'its', 'northernmost', 'end', ',', 'on', 'the', 'slopes', 'of', 'Mount', 'Lyell', '.'], 'coarse_tags': [0, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0], 'fine_tags': [0, 11, 11, 11, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0], 'id': '284'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in fewnerd[\"train\"].select(rows_with_mountain_tag[:5]):\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Replacing tags other than mountain tag with 0, mountain tags with 1, and removing extra columns from new datasets</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tag_map(tag):\n",
    "    return 1 if tag == MOUTAIN_TAG else 0\n",
    "\n",
    "def tag_list_map(tag_list):\n",
    "    return list(map(tag_map, tag_list))\n",
    "\n",
    "def fine_tags_map(examples):\n",
    "    examples[\"mountain_tags\"] = list(map(tag_list_map, examples[\"fine_tags\"]))    \n",
    "    return examples\n",
    "    \n",
    "fewnerd_mountains = fewnerd.map(fine_tags_map, remove_columns=[\"coarse_tags\", \"fine_tags\", \"id\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Some examples from the processed train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'Eighth', 'Army', 'began', 'to', 'attack', 'Italian', 'units', ',', 'located', 'using', 'information', 'from', 'Ultra', ',', 'at', 'Ruweisat', 'Ridge', 'and', 'from', 'again', 'at', 'Tel', 'El', 'Eisa', 'on', '22', 'July', 'and', 'Miteirya', 'Ridge', 'after', 'which', 'another', 'lull', 'fell', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['Mount', 'Diablo', 'has', 'inspired', 'many', 'artists', 'and', 'writers', '.'], 'mountain_tags': [1, 1, 0, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['K2', 'is', 'further', 'north', 'than', 'the', 'Himalayan', 'mountains', 'so', 'the', 'climate', 'is', 'colder', ';', 'the', 'Karakoram', 'range', 'is', 'wider', 'than', 'the', 'Himalayan', 'so', 'more', 'ice', 'and', 'snow', 'is', 'trapped', 'there', '.'], 'mountain_tags': [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['The', 'North', 'Lyell', 'Mine', ',', 'scene', 'of', 'the', '1912', 'North', 'Mount', 'Lyell', 'Disaster', 'was', 'at', 'its', 'northernmost', 'end', ',', 'on', 'the', 'slopes', 'of', 'Mount', 'Lyell', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in fewnerd_mountains[\"train\"].select(rows_with_mountain_tag[:5]):\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Computing number of mountain and O tags in processed datasets and their proportion</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset - mountain tags: 4500, O tags: 3223038, proportion: 0.0013961982452580454\n",
      "val   dataset - mountain tags: 734, O tags: 462386, proportion: 0.0015874183041874104\n",
      "test  dataset - mountain tags: 1366, O tags: 919688, proportion: 0.0014852863144892616\n"
     ]
    }
   ],
   "source": [
    "def print_mountain_dataset_stat(name, dataset):\n",
    "    mountain_tags_num = 0\n",
    "    tags_num = 0\n",
    "    for tags in dataset[\"mountain_tags\"]:\n",
    "        mountain_tags_num += sum(tags)\n",
    "        tags_num += len(tags)\n",
    "    o_tags_num = tags_num - mountain_tags_num\n",
    "    print(f\"{name:<5} dataset - mountain tags: {mountain_tags_num}, O tags: {o_tags_num}, proportion: {mountain_tags_num/o_tags_num}\")\n",
    "\n",
    "for k in fewnerd_mountains.keys():\n",
    "    print_mountain_dataset_stat(k, fewnerd_mountains[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load DistilBERT tokenizer to preprocess the tokens field</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">An example of tokenization in action:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'] \n",
      "\n",
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
      "\n",
      "['[CLS]', 'though', 'only', 'in', 'length', ',', 'the', 'sal', '##aman', '##der', 'glacier', 'is', 'about', 'wide', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example = fewnerd_mountains[\"train\"][\"tokens\"][75]\n",
    "tokenized_input = tokenizer(example, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "print(example, \"\\n\")\n",
    "print(tokenized_input, \"\\n\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Tokenizer adds some special tokens [CLS] and [SEP] and the subword tokenization creates a mismatch between the input and labels. A single word corresponding to a single label may now be split into two subwords. We realign the tokens and labels and remove extra columns from new datasets.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The value that is ignored and does not contribute to the input gradient in CrossEntropyLoss\n",
    "IGNORE_INDEX = -100 \n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"mountain_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) # Map tokens to their respective word\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(IGNORE_INDEX) # Set the special tokens to IGNORE_INDEX\n",
    "            else:\n",
    "                label_ids.append(label[word_idx]) # Label each token of a given word\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "fewnerd_mountains = fewnerd_mountains.map(tokenize_and_align_labels, remove_columns=[\"tokens\", \"mountain_tags\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">An example from the processed train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(fewnerd_mountains[\"train\"][75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Set a data collator that will dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Before we start training a model, create a list of lables and dictionaries of label ids and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'location-mountain'] \n",
      "\n",
      "{0: 'O', 1: 'location-mountain'} \n",
      "\n",
      "{'O': 0, 'location-mountain': 1}\n"
     ]
    }
   ],
   "source": [
    "label_list = [id2fine_tag[str(0)], id2fine_tag[str(MOUTAIN_TAG)]]\n",
    "print(label_list, \"\\n\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "print(id2label, \"\\n\")\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load DistilBERT model with AutoModelForTokenClassification along with the number of expected labels, and the label mappings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Create a function that computes metrics from predictions and labels, ignoring labels for special tokens</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != IGNORE_INDEX]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [ [label_list[l] for l in label if l != IGNORE_INDEX] for label in labels ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)    \n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Due to the imbalance of mountain tags number and O tags number in the datasets, we want to use class weights in the loss function. For this we need a customization of Trainer class.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def __init__(self, tag_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tag_weights = tag_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, num_items_in_batch = None, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")       \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')        \n",
    "        \n",
    "        # Compute custom loss\n",
    "        weight=torch.tensor(self.tag_weights)\n",
    "        if torch.cuda.is_available():\n",
    "           weight = weight.cuda()\n",
    "        #    print(\"GPU Activate\")\n",
    "        loss_fun = torch.nn.CrossEntropyLoss(weight)\n",
    "        loss = loss_fun(logits.view(-1, model.config.num_labels), labels.view(-1))        \n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Set parameters for training the model, create an instance of CustomTrainer, train the model, and evaluate it on the test dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skorina.ka\\AppData\\Local\\Temp\\ipykernel_20512\\1443336891.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123540' max='123540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123540/123540 2:36:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.475104</td>\n",
       "      <td>0.623978</td>\n",
       "      <td>0.539458</td>\n",
       "      <td>0.998487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.544959</td>\n",
       "      <td>0.532623</td>\n",
       "      <td>0.998706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.525907</td>\n",
       "      <td>0.553134</td>\n",
       "      <td>0.539177</td>\n",
       "      <td>0.998746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.046169</td>\n",
       "      <td>0.643068</td>\n",
       "      <td>0.594005</td>\n",
       "      <td>0.617564</td>\n",
       "      <td>0.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.690217</td>\n",
       "      <td>0.692098</td>\n",
       "      <td>0.691156</td>\n",
       "      <td>0.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.053781</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.626703</td>\n",
       "      <td>0.659971</td>\n",
       "      <td>0.998978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.055568</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.594005</td>\n",
       "      <td>0.642121</td>\n",
       "      <td>0.998877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.061001</td>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.594005</td>\n",
       "      <td>0.632801</td>\n",
       "      <td>0.998831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.057025</td>\n",
       "      <td>0.664653</td>\n",
       "      <td>0.599455</td>\n",
       "      <td>0.630372</td>\n",
       "      <td>0.998866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.553134</td>\n",
       "      <td>0.606876</td>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.069350</td>\n",
       "      <td>0.686084</td>\n",
       "      <td>0.577657</td>\n",
       "      <td>0.627219</td>\n",
       "      <td>0.998866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071356</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.572207</td>\n",
       "      <td>0.621302</td>\n",
       "      <td>0.998873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075540</td>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.564033</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.998888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.682390</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>0.633577</td>\n",
       "      <td>0.998908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072587</td>\n",
       "      <td>0.676012</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>0.630814</td>\n",
       "      <td>0.998906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2353' max='2353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2353/2353 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skorina.ka\\AppData\\Local\\miniconda3\\envs\\python310\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03768905624747276,\n",
       " 'eval_precision': 0.6402266288951841,\n",
       " 'eval_recall': 0.6637298091042585,\n",
       " 'eval_f1': 0.6517664023071377,\n",
       " 'eval_accuracy': 0.9989287819946799,\n",
       " 'eval_runtime': 75.498,\n",
       " 'eval_samples_per_second': 498.649,\n",
       " 'eval_steps_per_second': 31.166,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "tag_weights = [0.1, 1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"train_output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tag_weights=tag_weights,\n",
    "    args=training_args,\n",
    "    train_dataset=fewnerd_mountains[\"train\"],\n",
    "    eval_dataset=fewnerd_mountains[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate(fewnerd_mountains[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Save the best model and tokenizer to the specified directory</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fewnerd-mountains-model\\\\tokenizer_config.json',\n",
       " 'fewnerd-mountains-model\\\\special_tokens_map.json',\n",
       " 'fewnerd-mountains-model\\\\vocab.txt',\n",
       " 'fewnerd-mountains-model\\\\added_tokens.json',\n",
       " 'fewnerd-mountains-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"fewnerd-mountains-model\"\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Сonclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">The model metrics for mountain NER are similar to the BERT metrics for all categories of named entities on supervised [Few-NERD](http://ningding97.github.io/fewnerd) dataset. So it seems that by changing the training parameters we can slightly improve the model performance, but a more significant performance improvement is only available by changing the base model from DistilBERT to another language model, such as RoBERTa or XLNet.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load the model and tokenizer from the specified path and define a function that tags each word in a text with either the mountain tag or the O tag</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"fewnerd-mountains-model\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Returns a list of word and tag pairs based on the model and tokenizer \n",
    "def get_word_tag_list(text):    \n",
    "    tokenized_input = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "    # Compute a list of predicted tags for all tokens based on the model \n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokenized_input).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    predicted_tags = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "\n",
    "    # List mapping token IDs to word IDs\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    \n",
    "    # Get a list mapping word IDs to token IDs\n",
    "    word_to_token_ids = []\n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is not None:\n",
    "            if word_id >= len(word_to_token_ids):\n",
    "                word_to_token_ids.append([])\n",
    "            word_to_token_ids[word_id].append(idx)\n",
    "\n",
    "    # Generate a list of word and tag pairs\n",
    "    word_tag_list = []    \n",
    "    for word_id in range(len(word_to_token_ids)):\n",
    "        span = tokenized_input.word_to_chars(word_id)\n",
    "        word = text[span.start:span.end]\n",
    "        \n",
    "        token_id = word_to_token_ids[word_id][0]\n",
    "        tag = predicted_tags[token_id]       \n",
    "        \n",
    "        word_tag_list.append((word, tag))\n",
    "\n",
    "    return word_tag_list     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Examples of the model output:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : O\n",
      "Golden : O\n",
      "State : O\n",
      "Warriors : O\n",
      "are : O\n",
      "an : O\n",
      "American : O\n",
      "professional : O\n",
      "basketball : O\n",
      "team : O\n",
      "based : O\n",
      "in : O\n",
      "San : O\n",
      "Francisco : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "# Prints the model output\n",
    "def print_word_tag_list(text):\n",
    "    word_tag_list = get_word_tag_list(text)\n",
    "    for p in word_tag_list:\n",
    "        print(f\"{p[0]} : {p[1]}\")\n",
    "\n",
    "text = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : O\n",
      "Mont : location-mountain\n",
      "Blanc : location-mountain\n",
      "massif : location-mountain\n",
      "is : O\n",
      "popular : O\n",
      "for : O\n",
      "outdoor : O\n",
      "activities : O\n",
      "like : O\n",
      "hiking : O\n",
      ", : O\n",
      "climbing : O\n",
      ", : O\n",
      "trail : O\n",
      "running : O\n",
      "and : O\n",
      "winter : O\n",
      "sports : O\n",
      "like : O\n",
      "skiing : O\n",
      ", : O\n",
      "and : O\n",
      "snowboarding : O\n",
      ". : O\n",
      "The : O\n",
      "most : O\n",
      "popular : O\n",
      "climbing : O\n",
      "route : O\n",
      "to : O\n",
      "the : O\n",
      "summit : O\n",
      "of : O\n",
      "Mont : location-mountain\n",
      "Blanc : location-mountain\n",
      "is : O\n",
      "the : O\n",
      "Goûter : O\n",
      "Route : O\n",
      ", : O\n",
      "which : O\n",
      "typically : O\n",
      "takes : O\n",
      "two : O\n",
      "days : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" \n",
    "The Mont Blanc massif is popular for outdoor activities like hiking, climbing, trail running and winter sports like skiing, and snowboarding.\n",
    "The most popular climbing route to the summit of Mont Blanc is the Goûter Route, which typically takes two days.\n",
    "\"\"\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mont : O\n",
      "Blanc : O\n",
      "is : O\n",
      "a : O\n",
      "beautiful : O\n",
      "rooftop : O\n",
      "cafe : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "text = \"Mont Blanc is a beautiful rooftop cafe.\"\n",
    "print_word_tag_list(text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1383328,
     "sourceId": 2297849,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
